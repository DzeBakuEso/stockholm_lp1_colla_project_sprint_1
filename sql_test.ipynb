{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing your data from the database\n",
    "\n",
    "- Please follow the steps in this notebook to have access to the dataset. \n",
    "- If you encounter any challenges please leave an issue on this repo here on GitHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to take to use environment variables as opposed to credentials literals\n",
    "\n",
    "1. Install pyodbc  - a package for creating connection strings to your remote database\n",
    "2. Install python-dotenv - a package for creating environment variables that will help you hide sensitve configuration informantion such as database credentials and API keys\n",
    "3. Import all the necessary libraies\n",
    "   1. pyodbc (for creating a connection)\n",
    "   2. python-dotenv (loading environment variables)\n",
    "   3. os (for accessing the environement variables using the load_env function. This is not needed if you use the dotenv_values function instead)\n",
    "4. Now create a file called .env in the root of your project folder (Note, the file name begins with a dot)\n",
    "5. In the .env file, put all your sensitive information like server name, database name, username, and password\n",
    "\n",
    "Example\n",
    "\n",
    "   - SERVER='server_name_here'\n",
    "   - DATABASE='database_name_here'\n",
    "   - USERNAME='username_here'\n",
    "   - PASSWORD='password_here'\n",
    "\n",
    "\n",
    "6. Next create a .gitignore file (a new file with the name '.gitignore'. Note that gitignore file names begin with a dot)\n",
    "7. Open the .gitignore file and type in the name of the .env file we just create like this \"/.env\". This will prevent git from tracking that file. Essesntially any file name in the gitignore file will be ignored by git and won't be checked into the repository\n",
    "8. Create a connection by accessing your connection string with your defined environment variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 and 2 - Install pyodbc and python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyodbc  \n",
    "%pip install python-dotenv \n",
    "%pip install pandas "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 - Import all the necessary packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc #just installed with pip\n",
    "from dotenv import dotenv_values #import the dotenv_values function from the dotenv package\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 - Create your .env file in the root of your project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 - In the .env file, put all your sensitive information like server name, password etc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 & 7 - Next create a .gitignore file and type '/.env' file we just created. This will prevent git from tracking that file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 - Create a connection by accessing your connection string with your defined environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "\n",
    "\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "# This will connect to the server and might take a few seconds to be complete. \n",
    "# Check your internet connection if it takes more time than necessary\n",
    "\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the sql query to get the data is what what you see below. \n",
    "# Note that you will not have permissions to insert delete or update this database table. \n",
    "query1 = \"SELECT * FROM dbo.LP1_startup_funding2020\"\n",
    "query2 = \"SELECT * FROM dbo.LP1_startup_funding2021\"\n",
    "data1 = pd.read_sql(query1, connection)\n",
    "data2 = pd.read_sql(query2, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can concatenate this with other DataFrames to get one data set for your work\n",
    "\n",
    "df = pd.concat([data1, data2])\n",
    "df.to_csv('aba.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
