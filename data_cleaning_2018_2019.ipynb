{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing packages\n",
    "\n",
    "%pip install matplotlib \n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoporting packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('startup_funding2018.csv') # read the data_2018 and convert it to pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('startup_funding2019.csv') # read the data_2019 and convert it to pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  # View the first few rows of the DataFrame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head() # View the first few rows of the DataFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  # Get information about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info() # Get inforamation about the data2 dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')  # Generate descriptive statistics of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe(include='object') # General descriptive statistics of the data2 dataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have some description about the data set, we can now move on with data cleaning\n",
    " \n",
    "MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum() # looking for missing values \n",
    "\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values2 = df2.isnull().sum() # looking for missing values in dataFrame 2\n",
    "missing_values2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Data Formats\n",
    "\n",
    "now let's see how we can standardize tha data set to make sure we have the same format of data points "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's check for dash symbols within the columns using a simple python function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Amount', 'Company Name', 'Location', 'About Company', 'Industry', 'Round/Series']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    has_dash_symbols = df[column].str.contains('—').any()\n",
    "    print(f\"{column}: {has_dash_symbols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for '-' symbol within the columns\n",
    "\n",
    "columns_to_check2 = ['Company/Brand', 'Founded', 'HeadQuarter', 'Sector', 'What it does', 'Founders', 'Investor', 'Amount($)', 'Stage']\n",
    "\n",
    "for column2 in columns_to_check2:\n",
    "    has_dash_symbols2 = df2[column2].astype(str).str.contains('-').any()\n",
    "    print(f'{column2}: {has_dash_symbols2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for currency symbol \n",
    "\n",
    "columns_to_check2 = ['Company/Brand', 'Founded', 'HeadQuarter', 'Sector', 'What it does', 'Founders', 'Investor', 'Amount($)']\n",
    "\n",
    "for column2 in columns_to_check2:\n",
    "    has_currency_symbols = df2[column2].astype(str).str.contains('[$₹]').any()\n",
    "    print(f'{column2}: {has_currency_symbols}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the '-' symbols using a simple function \n",
    "\n",
    "dash_currency_columns = ['Sector', 'What it does', 'Founders', 'Investor', 'Stage']\n",
    "\n",
    "for dash_columns2 in dash_currency_columns:\n",
    "    dash_replaced2 = df2[dash_columns2].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's handle the dash symbols in the Amount column, clean and format the amount the column correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = df['Amount'].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove currency symbols and commas, and convert to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)'] = df2['Amount($)'].astype(str).str.replace('[\\₹$,]', '', regex=True)  # removing the currency symbol from the Amount in dataFrame2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = df['Amount'].str.replace('[\\₹$,]', '', regex=True) # Remove currency symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = df['Amount'].replace('—', np.nan) # Replace dash symbol with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = df['Amount'].astype(float) # Convert remaining values to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Amount']) # Verify the updated 'Amount' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2['Amount($)']) # Verify the updated 'Amount($)' column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW LET'S \n",
    "\n",
    "handle the categorical data in the 'Industry', 'Round/Series', and 'Location' columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing unique values\n",
    "Start by examining the unique values in each column to identify any inconsistencies or variations we do this \n",
    "Using the unique() function to get the unique values in each column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW IS FOF DATA SET ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Industry'].unique())\n",
    "print(df['Round/Series'].unique())\n",
    "#print(df['Location'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO understand categoriacl data and how to deal with them \n",
    "\n",
    "Categorical data refers to a type of data that represents qualitative or nominal variables. These variables have distinct categories or groups and do not have a natural numerical order. Categorical data is often represented by labels or names and can be further divided into several subtypes:\n",
    "\n",
    "1. Nominal data: It consists of categories without any specific order or ranking. Examples include gender (male, female, other), color (red, blue, green), or country (USA, Canada, India). Nominal data represents distinct groups, but the categories are not inherently ranked or ordered.\n",
    "\n",
    "2. Ordinal: Ordinal data also represents categories, but they have a meaningful order or ranking. The numerical values assigned to ordinal variables indicate the relative position or preference but not the magnitude of the differences between them. Examples include education level (high school, bachelor's degree, master's degree), customer satisfaction rating (poor, fair, good, excellent), or economic status (low income, middle income, high income).\n",
    "   \n",
    "BASE ON THE FIRST data set, the following columns can be considered as a categorical columns \n",
    "\n",
    "1. Company Name: Nominal categorical data. Each company name represents a distinct category without any specific order or ranking.\n",
    "\n",
    "2. Industry: Nominal categorical data. The industry categories represent different sectors without any inherent order or hierarchy.\n",
    "\n",
    "3. Round/Series: Ordinal categorical data. The funding rounds or series can be ranked based on their order or progression (e.g., Seed, Series A, Series B), indicating a meaningful order.\n",
    "\n",
    "4. Location: Nominal categorical data. The locations represent different geographical regions without any particular order or ranking.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW LET'S CLEAN THE CATEGORICAL COLUMNS\n",
    "\n",
    "1. NOMINAL TYPES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_columns = ['Industry', 'Location']\n",
    "\n",
    "nominal_filter = df[nominal_columns]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW LET'S DEAL WITH DUPLICATED ROWS \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW IS FOR DATA1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['Company Name', 'Industry', 'Round/Series', 'Amount', 'Location', 'About Company']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    has_duplicates = df[column].duplicated().any()\n",
    "    print(f'{column}: {has_duplicates}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Company Name', 'Industry', 'Round/Series', 'Amount', 'Location', 'About Company'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW IS FOR DATA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check2 = ['Company/Brand', 'Founded', 'HeadQuarter', 'Sector', 'What it does', 'Founders', 'Investor', 'Amount($)', 'Stage',]\n",
    "\n",
    "for column2 in columns_to_check2:\n",
    "    has_duplicates2 = df2[column2].duplicated().any()\n",
    "    print(f'{column2}: {has_duplicates2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset=['Company/Brand', 'Founded', 'HeadQuarter', 'Sector', 'What it does', 'Founders', 'Investor', 'Amount($)', 'Stage',], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
