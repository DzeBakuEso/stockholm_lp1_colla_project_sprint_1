{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCKHOLM TEAM\n",
    "\n",
    "## Exploratory Data Analysis of the Indian StartUp Funding Ecosystem "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Description:**\n",
    "\n",
    "Explore the Indian startup funding ecosystem through an in-depth analysis of funding data from 2019 to 2021. Gain insights into key trends, funding patterns, and factors driving startup success. Investigate the relationship between funding and startup growth, with a focus on temporal patterns and city-level dynamics. Identify preferred sectors for investment and uncover industry-specific funding trends. This exploratory data analysis provides a comprehensive overview of the Indian startup ecosystem, offering valuable insights for entrepreneurs, investors, and policymakers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "This project aims to explore and gain a deeper understanding of the Indian startup funding ecosystem. The dataset used for analysis contains information about startup funding from 2019 to 2021. The dataset includes various attributes such as the company's name, sector, funding amount, funding round, investor details, and location.\n",
    "\n",
    "To conduct a comprehensive analysis, we will examine the dataset to understand its structure, contents, and any potential data quality issues. By understanding the data, we can ensure the accuracy and reliability of our analysis.\n",
    "\n",
    "The key attributes in the dataset include:\n",
    "\n",
    "- **Company**: The name of the startup receiving funding.\n",
    "- **Sector**: The industry or sector to which the startup belongs.\n",
    "- **Amount**: The amount of funding received by the startup.\n",
    "- **Stage**: The round of funding (e.g., seed, series A, series B).\n",
    "- **Location**: The city or region where the startup is based.\n",
    "- **About**: What the company does.\n",
    "\n",
    "By examining these attributes, we can uncover insights about the funding landscape, identify trends in funding amounts and rounds, explore the preferred sectors for investment, and analyze the role of cities in the startup ecosystem.\n",
    "\n",
    "Throughout the analysis, we will use visualizations and statistical techniques to present the findings effectively. By understanding the data and its characteristics, we can proceed with confidence in our analysis, derive meaningful insights, and make informed decisions based on the findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "\n",
    "#### NULL Hypothesis (HO) :\n",
    "\n",
    "#### **The sector of a company does not have an impact on the amount of funding it receives.**\n",
    "\n",
    "\n",
    "#### ALTERNATE Hypothesis (HA):\n",
    "\n",
    "#### **The sector of a company does have an impact on the amount of funding it receives.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Research / Analysis Questions:\n",
    "\n",
    "1. What are the most common industries represented in the datasets?\n",
    "\n",
    "2. How does the funding amount vary across different rounds/series in the datasets?\n",
    "   \n",
    "3. Which locations have the highest number of companies in the datasets?\n",
    "   \n",
    "4. What kind of investment type should startups look for depending on their industry type? (EDA: Analysis of funding preferences by industry)\n",
    "\n",
    "5. Are there any correlations between the funding amount and the company's sector or location?\n",
    "   \n",
    "6. What are the top investors in the datasets based on the number of investments made?\n",
    "   \n",
    "7. Which industries are favored by investors based on the number of funding rounds? (EDA: Top 10 industries which are favored by investors)\n",
    "\n",
    "8. Are there any outliers in the funding amounts in the datasets?\n",
    "   \n",
    "9.  Is there a relationship between the company's sector and the presence of certain investors?\n",
    "    \n",
    "10. What is the range of funds generally received by startups in India (Max, min, avg, and count of funding)? (EDA: Descriptive statistics of funding amounts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before diving into the analysis, we will preprocess and clean the data to ensure its quality and suitability for analysis. This may involve handling missing values, correcting data types, and addressing any inconsistencies or outliers that could affect the accuracy of our results.\n",
    "\n",
    "Once the data is prepared, we will be ready to perform an in-depth exploratory analysis of the Indian startup funding ecosystem. The analysis will involve answering specific research questions, identifying patterns and trends, and generating meaningful visualizations to present the findings.\n",
    "\n",
    "Through this process of data understanding and preparation, we will set a solid foundation for conducting a robust and insightful analysis of the Indian startup funding data.\n",
    "\n",
    "**The data for each year is sourced from separate two csv files and two from a remote server. They will be merged later to one dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Packages/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Modules needed\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import pyodbc #just installed with pip\n",
    "from dotenv import dotenv_values #import the dotenv_values function from the dotenv package\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from forex_python.converter import CurrencyRates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('startup_funding2018.csv') # read the data_2018 and convert it to pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('startup_funding2019.csv') # read the data_2019 and convert it to pandas data frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acessing the Remote Server Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")\n",
    "\n",
    "\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "# This will connect to the server and might take a few seconds to be complete. \n",
    "# Check your internet connection if it takes more time than necessary\n",
    "\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the sql query to get the data is what what you see below. \n",
    "# Note that you will not have permissions to insert delete or update this database table. \n",
    "query1 = \"SELECT * FROM dbo.LP1_startup_funding2020\"\n",
    "query2 = \"SELECT * FROM dbo.LP1_startup_funding2021\"\n",
    "df3 = pd.read_sql(query1, connection)\n",
    "df4 = pd.read_sql(query2, connection)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry   \n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...  \\\n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      PayMe India                        Financial Services, FinTech   \n",
       "4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  Round/Series       Amount                          Location   \n",
       "0         Seed       250000       Bangalore, Karnataka, India  \\\n",
       "1         Seed  ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2     Series A  ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3        Angel      2000000       Noida, Uttar Pradesh, India   \n",
       "4         Seed            —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       About Company  \n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...  \n",
       "1  A startup which aggregates milk from dairy far...  \n",
       "2          Leading Online Loans Marketplace in India  \n",
       "3  PayMe India is an innovative FinTech organizat...  \n",
       "4  Eunimart is a one stop solution for merchants ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company Name', 'Industry', 'Round/Series', 'Amount', 'Location',\n",
       "       'About Company'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   526 non-null    object\n",
      " 1   Industry       526 non-null    object\n",
      " 2   Round/Series   526 non-null    object\n",
      " 3   Amount         526 non-null    object\n",
      " 4   Location       526 non-null    object\n",
      " 5   About Company  526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # Get information about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>525</td>\n",
       "      <td>405</td>\n",
       "      <td>21</td>\n",
       "      <td>198</td>\n",
       "      <td>50</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>—</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>280</td>\n",
       "      <td>148</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company Name Industry Round/Series Amount   \n",
       "count               526      526          526    526  \\\n",
       "unique              525      405           21    198   \n",
       "top     TheCollegeFever        —         Seed      —   \n",
       "freq                  2       30          280    148   \n",
       "\n",
       "                           Location   \n",
       "count                           526  \\\n",
       "unique                           50   \n",
       "top     Bangalore, Karnataka, India   \n",
       "freq                            102   \n",
       "\n",
       "                                            About Company  \n",
       "count                                                 526  \n",
       "unique                                                524  \n",
       "top     TheCollegeFever is a hub for fun, fiesta and f...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')  # Generate descriptive statistics of the DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have some description about the data set, we can now move on with data cleaning\n",
    " \n",
    "MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name     0\n",
      "Industry         0\n",
      "Round/Series     0\n",
      "Amount           0\n",
      "Location         0\n",
      "About Company    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum() # looking for missing values \n",
    "\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Data Formats\n",
    "\n",
    "now let's see how we can standardize tha data set to make sure we have the same format of data points "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's check for dash symbols within the columns using a simple python function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount: True\n",
      "Company Name: False\n",
      "Location: False\n",
      "About Company: False\n",
      "Industry: True\n",
      "Round/Series: False\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['Amount', 'Company Name', 'Location', 'About Company', 'Industry', 'Round/Series']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    has_dash_symbols = df[column].str.contains('—').any()\n",
    "    print(f\"{column}: {has_dash_symbols}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's handle the dash symbols in **the Amount column**, clean and format the amount the column correctly & Convert Currency to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         250000\n",
       "1    ₹40,000,000\n",
       "2    ₹65,000,000\n",
       "3        2000000\n",
       "4              —\n",
       "Name: Amount, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Amounts column\n",
    "df['Amount'] = df['Amount'].apply(str)\n",
    "df['Amount'].replace(\",\", \"\", inplace = True, regex=True)\n",
    "df['Amount'].replace(\"—\", 0, inplace = True, regex=True)\n",
    "df['Amount'].replace(\"$\", \"\", inplace = True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CurrencyRates\n",
    "c = CurrencyRates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating temporary columns to help with the conversion of INR to USD\n",
    "df['Indiancurr'] = df['Amount'].str.rsplit('₹', n=2).str[1]\n",
    "df['Indiancurr'] = df['Indiancurr'].apply(float).fillna(0)\n",
    "df['UsCurr'] = df['Indiancurr'] * c.get_rate('INR', 'USD')\n",
    "df['UsCurr'] = df['UsCurr'].replace(0, np.nan)\n",
    "df['UsCurr'] = df['UsCurr'].fillna(df['Amount'])\n",
    "df['UsCurr'] = df['UsCurr'].replace(\"$\", \"\", regex=True)\n",
    "df['Amount'] = df['UsCurr']\n",
    "df['Amount'] = df['Amount'].apply(lambda x: float(str(x).replace(\"$\",\"\")))\n",
    "df['Amount'] = df['Amount'].replace(0, np.nan)\n",
    "\n",
    "# Define a lambda function to format the amount\n",
    "format_amount = lambda amount: \"{:,.2f}\".format(amount)\n",
    "\n",
    "# Apply the formatting lambda function to the 'Amount' column\n",
    "df['Amount'] = df['Amount'].map(format_amount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      250,000.00\n",
       "1      485,093.94\n",
       "2      788,277.65\n",
       "3    2,000,000.00\n",
       "4             nan\n",
       "Name: Amount, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Amount'] = df['Amount'].str.replace(',', '').astype(float)\n",
    "type(df['Amount'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Categorical Data\n",
    "NOW LET'S \n",
    "\n",
    "handle the categorical data in the 'Industry', 'Round/Series', and 'Location' columns\n",
    "\n",
    "Analyzing unique values\n",
    "Start by examining the unique values in each column to identify any inconsistencies or variations we do this \n",
    "Using the unique() function to get the unique values in each column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore, Karnataka, India', 'Mumbai, Maharashtra, India',\n",
       "       'Gurgaon, Haryana, India', 'Noida, Uttar Pradesh, India',\n",
       "       'Hyderabad, Andhra Pradesh, India', 'Bengaluru, Karnataka, India',\n",
       "       'Kalkaji, Delhi, India', 'Delhi, Delhi, India', 'India, Asia',\n",
       "       'Hubli, Karnataka, India', 'New Delhi, Delhi, India',\n",
       "       'Chennai, Tamil Nadu, India', 'Mohali, Punjab, India',\n",
       "       'Kolkata, West Bengal, India', 'Pune, Maharashtra, India',\n",
       "       'Jodhpur, Rajasthan, India', 'Kanpur, Uttar Pradesh, India',\n",
       "       'Ahmedabad, Gujarat, India', 'Azadpur, Delhi, India',\n",
       "       'Haryana, Haryana, India', 'Cochin, Kerala, India',\n",
       "       'Faridabad, Haryana, India', 'Jaipur, Rajasthan, India',\n",
       "       'Kota, Rajasthan, India', 'Anand, Gujarat, India',\n",
       "       'Bangalore City, Karnataka, India', 'Belgaum, Karnataka, India',\n",
       "       'Thane, Maharashtra, India', 'Margão, Goa, India',\n",
       "       'Indore, Madhya Pradesh, India', 'Alwar, Rajasthan, India',\n",
       "       'Kannur, Kerala, India', 'Trivandrum, Kerala, India',\n",
       "       'Ernakulam, Kerala, India', 'Kormangala, Karnataka, India',\n",
       "       'Uttar Pradesh, India, Asia', 'Andheri, Maharashtra, India',\n",
       "       'Mylapore, Tamil Nadu, India', 'Ghaziabad, Uttar Pradesh, India',\n",
       "       'Kochi, Kerala, India', 'Powai, Assam, India',\n",
       "       'Guntur, Andhra Pradesh, India', 'Kalpakkam, Tamil Nadu, India',\n",
       "       'Bhopal, Madhya Pradesh, India', 'Coimbatore, Tamil Nadu, India',\n",
       "       'Worli, Maharashtra, India', 'Alleppey, Kerala, India',\n",
       "       'Chandigarh, Chandigarh, India', 'Guindy, Tamil Nadu, India',\n",
       "       'Lucknow, Uttar Pradesh, India'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Bangalore, Karnataka, India         102\n",
       "Mumbai, Maharashtra, India           94\n",
       "Bengaluru, Karnataka, India          55\n",
       "Gurgaon, Haryana, India              52\n",
       "New Delhi, Delhi, India              51\n",
       "Pune, Maharashtra, India             20\n",
       "Chennai, Tamil Nadu, India           19\n",
       "Hyderabad, Andhra Pradesh, India     18\n",
       "Delhi, Delhi, India                  16\n",
       "Noida, Uttar Pradesh, India          15\n",
       "Haryana, Haryana, India              11\n",
       "Jaipur, Rajasthan, India              9\n",
       "Ahmedabad, Gujarat, India             6\n",
       "Kolkata, West Bengal, India           6\n",
       "Bangalore City, Karnataka, India      5\n",
       "Indore, Madhya Pradesh, India         4\n",
       "India, Asia                           4\n",
       "Kormangala, Karnataka, India          3\n",
       "Ghaziabad, Uttar Pradesh, India       2\n",
       "Kochi, Kerala, India                  2\n",
       "Bhopal, Madhya Pradesh, India         2\n",
       "Thane, Maharashtra, India             2\n",
       "Jodhpur, Rajasthan, India             1\n",
       "Powai, Assam, India                   1\n",
       "Andheri, Maharashtra, India           1\n",
       "Mylapore, Tamil Nadu, India           1\n",
       "Kalpakkam, Tamil Nadu, India          1\n",
       "Guntur, Andhra Pradesh, India         1\n",
       "Coimbatore, Tamil Nadu, India         1\n",
       "Worli, Maharashtra, India             1\n",
       "Alleppey, Kerala, India               1\n",
       "Chandigarh, Chandigarh, India         1\n",
       "Guindy, Tamil Nadu, India             1\n",
       "Uttar Pradesh, India, Asia            1\n",
       "Trivandrum, Kerala, India             1\n",
       "Ernakulam, Kerala, India              1\n",
       "Kanpur, Uttar Pradesh, India          1\n",
       "Kannur, Kerala, India                 1\n",
       "Alwar, Rajasthan, India               1\n",
       "Margão, Goa, India                    1\n",
       "Belgaum, Karnataka, India             1\n",
       "Kalkaji, Delhi, India                 1\n",
       "Anand, Gujarat, India                 1\n",
       "Kota, Rajasthan, India                1\n",
       "Faridabad, Haryana, India             1\n",
       "Cochin, Kerala, India                 1\n",
       "Hubli, Karnataka, India               1\n",
       "Azadpur, Delhi, India                 1\n",
       "Mohali, Punjab, India                 1\n",
       "Lucknow, Uttar Pradesh, India         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Location' column is in the format, 'City, Region, Country',\n",
    "# Only 'City' aspect is needed for this analysis\n",
    "# Take all character until we reach the first comma sign\n",
    "\n",
    "df['Location'] = df['Location'].apply(str)\n",
    "df['Location'] = df['Location'].str.split(',').str[0]\n",
    "df['Location'] = df['Location'].replace(\"'\",\"\",regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Bangalore\n",
       "1         Mumbai\n",
       "2        Gurgaon\n",
       "3          Noida\n",
       "4      Hyderabad\n",
       "         ...    \n",
       "521    Bangalore\n",
       "522      Haryana\n",
       "523       Mumbai\n",
       "524       Mumbai\n",
       "525      Chennai\n",
       "Name: Location, Length: 526, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From obersavtion, there is use of official and unofficial names of certain cities.\n",
    "# The incorrect names need to be rectified for correct analysis, eg A city with more than one name.\n",
    "df[\"Location\"] = df[\"Location\"].replace (['Bangalore','Bangalore City','Belgaum'], 'Bengaluru')\n",
    "df['Location'] = df['Location'].str.replace('New Delhi','Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bengaluru', 'Mumbai', 'Gurgaon', 'Noida', 'Hyderabad', 'Kalkaji',\n",
       "       'Delhi', 'India', 'Hubli', 'Chennai', 'Mohali', 'Kolkata', 'Pune',\n",
       "       'Jodhpur', 'Kanpur', 'Ahmedabad', 'Azadpur', 'Haryana', 'Cochin',\n",
       "       'Faridabad', 'Jaipur', 'Kota', 'Anand', 'Thane', 'Margão',\n",
       "       'Indore', 'Alwar', 'Kannur', 'Trivandrum', 'Ernakulam',\n",
       "       'Kormangala', 'Uttar Pradesh', 'Andheri', 'Mylapore', 'Ghaziabad',\n",
       "       'Kochi', 'Powai', 'Guntur', 'Kalpakkam', 'Bhopal', 'Coimbatore',\n",
       "       'Worli', 'Alleppey', 'Chandigarh', 'Guindy', 'Lucknow'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Bengaluru        163\n",
       "Mumbai            94\n",
       "Delhi             67\n",
       "Gurgaon           52\n",
       "Pune              20\n",
       "Chennai           19\n",
       "Hyderabad         18\n",
       "Noida             15\n",
       "Haryana           11\n",
       "Jaipur             9\n",
       "Kolkata            6\n",
       "Ahmedabad          6\n",
       "India              4\n",
       "Indore             4\n",
       "Kormangala         3\n",
       "Bhopal             2\n",
       "Kochi              2\n",
       "Ghaziabad          2\n",
       "Thane              2\n",
       "Faridabad          1\n",
       "Mylapore           1\n",
       "Guindy             1\n",
       "Chandigarh         1\n",
       "Alleppey           1\n",
       "Worli              1\n",
       "Coimbatore         1\n",
       "Kalkaji            1\n",
       "Kalpakkam          1\n",
       "Guntur             1\n",
       "Powai              1\n",
       "Hubli              1\n",
       "Mohali             1\n",
       "Andheri            1\n",
       "Cochin             1\n",
       "Uttar Pradesh      1\n",
       "Jodhpur            1\n",
       "Ernakulam          1\n",
       "Trivandrum         1\n",
       "Kannur             1\n",
       "Alwar              1\n",
       "Kanpur             1\n",
       "Margão             1\n",
       "Azadpur            1\n",
       "Anand              1\n",
       "Kota               1\n",
       "Lucknow            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Brand Marketing, Event Promotion, Marketing, S...\n",
       "1                                   Agriculture, Farming\n",
       "2       Credit, Financial Services, Lending, Marketplace\n",
       "3                            Financial Services, FinTech\n",
       "4                     E-Commerce Platforms, Retail, SaaS\n",
       "                             ...                        \n",
       "521     B2B, Business Development, Internet, Marketplace\n",
       "522                                      Tourism, Travel\n",
       "523           Food and Beverage, Food Delivery, Internet\n",
       "524                               Information Technology\n",
       "525           Biotechnology, Health Care, Pharmaceutical\n",
       "Name: Industry, Length: 526, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' with NaN\n",
    "df['Industry'].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Indiancurr','UsCurr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(6,\"Funding Year\", 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Company Name':'Company',\n",
    "                        'Industry':'Sector',\n",
    "                        'Amount':'Amount',\n",
    "                        'About Company':'About',\n",
    "                        'Round/Series' : 'Stage'},\n",
    "             inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company/Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What it does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount($)</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bombay Shaving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ecommerce</td>\n",
       "      <td>Provides a range of male grooming products</td>\n",
       "      <td>Shantanu Deshpande</td>\n",
       "      <td>Sixth Sense Ventures</td>\n",
       "      <td>$6,300,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruangguru</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>A learning platform that provides topic-based ...</td>\n",
       "      <td>Adamas Belva Syah Devara, Iman Usman.</td>\n",
       "      <td>General Atlantic</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eduisfun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>It aims to make learning fun via games.</td>\n",
       "      <td>Jatin Solanki</td>\n",
       "      <td>Deepak Parekh, Amitabh Bachchan, Piyush Pandey</td>\n",
       "      <td>$28,000,000</td>\n",
       "      <td>Fresh funding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HomeLane</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Interior design</td>\n",
       "      <td>Provides interior designing solutions</td>\n",
       "      <td>Srikanth Iyer, Rama Harinath</td>\n",
       "      <td>Evolvence India Fund (EIF), Pidilite Group, FJ...</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nu Genes</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>It is a seed company engaged in production, pr...</td>\n",
       "      <td>Narayana Reddy Punyala</td>\n",
       "      <td>Innovation in Food and Agriculture (IFA)</td>\n",
       "      <td>$6,000,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company/Brand  Founded HeadQuarter           Sector   \n",
       "0  Bombay Shaving      NaN         NaN        Ecommerce  \\\n",
       "1       Ruangguru   2014.0      Mumbai           Edtech   \n",
       "2        Eduisfun      NaN      Mumbai           Edtech   \n",
       "3        HomeLane   2014.0     Chennai  Interior design   \n",
       "4        Nu Genes   2004.0   Telangana         AgriTech   \n",
       "\n",
       "                                        What it does   \n",
       "0         Provides a range of male grooming products  \\\n",
       "1  A learning platform that provides topic-based ...   \n",
       "2            It aims to make learning fun via games.   \n",
       "3              Provides interior designing solutions   \n",
       "4  It is a seed company engaged in production, pr...   \n",
       "\n",
       "                                Founders   \n",
       "0                     Shantanu Deshpande  \\\n",
       "1  Adamas Belva Syah Devara, Iman Usman.   \n",
       "2                          Jatin Solanki   \n",
       "3           Srikanth Iyer, Rama Harinath   \n",
       "4                 Narayana Reddy Punyala   \n",
       "\n",
       "                                            Investor     Amount($)   \n",
       "0                               Sixth Sense Ventures    $6,300,000  \\\n",
       "1                                   General Atlantic  $150,000,000   \n",
       "2     Deepak Parekh, Amitabh Bachchan, Piyush Pandey   $28,000,000   \n",
       "3  Evolvence India Fund (EIF), Pidilite Group, FJ...   $30,000,000   \n",
       "4           Innovation in Food and Agriculture (IFA)    $6,000,000   \n",
       "\n",
       "           Stage  \n",
       "0            NaN  \n",
       "1       Series C  \n",
       "2  Fresh funding  \n",
       "3       Series D  \n",
       "4            NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info() # Get inforamation about the data2 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe(include='object') # General descriptive statistics of the data2 dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the columns that are not important to our analysis including an unnamed column\n",
    "\n",
    "df2.drop(columns=['Founded','Founders','Investor'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have some description about the data set, we can now move on with data cleaning\n",
    " \n",
    "MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values2 = df2.isnull().sum() # looking for missing values in dataFrame 2\n",
    "missing_values2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LET'S DEAL WITH THE MISSING VALUES FROM THE ABOVE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace specific values with NaN\n",
    "df2['HeadQuarter'].replace('Not available', np.nan, inplace=True)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df2['Sector'].replace('', np.nan, inplace=True)\n",
    "df2['Stage'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Data Formats\n",
    "\n",
    "now let's see how we can standardize tha data set to make sure we have the same format of data points "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's check for dash symbols within the columns using a simple python function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for '-' symbol within the columns\n",
    "\n",
    "columns_to_check2 = ['Company/Brand', 'HeadQuarter', 'Sector', 'What it does', 'Amount($)', 'Stage']\n",
    "\n",
    "for column2 in columns_to_check2:\n",
    "    has_dash_symbols2 = df2[column2].astype(str).str.contains('-').any()\n",
    "    print(f'{column2}: {has_dash_symbols2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for currency symbol \n",
    "\n",
    "columns_to_check2 = ['Company/Brand','HeadQuarter', 'Sector', 'What it does', 'Amount($)']\n",
    "\n",
    "for column2 in columns_to_check2:\n",
    "    has_currency_symbols = df2[column2].astype(str).str.contains('[$₹]').any()\n",
    "    print(f'{column2}: {has_currency_symbols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the '-' symbols using a simple function \n",
    "\n",
    "dash_currency_columns = ['Sector', 'What it does', 'Stage']\n",
    "\n",
    "for dash_columns2 in dash_currency_columns:\n",
    "    dash_replaced2 = df2[dash_columns2].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's handle the dash symbols in the Amount column, clean and format the amount the column correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)'] = df2['Amount($)'].astype(str).str.replace('[\\₹$,]', '', regex=True)  # removing the currency symbol from the Amount in dataFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the Amounts column & # removing the currency symbol in df_2019\n",
    "df2['Amount($)'] = df2['Amount($)'].apply(str)\n",
    "df2['Amount($)'].replace(\",\", \"\", inplace = True, regex=True)\n",
    "df2['Amount($)'].replace(\"—\", 0, inplace = True, regex=True)\n",
    "df2['Amount($)'].replace(\"$\", \"\", inplace = True, regex=True)\n",
    "df2['Amount($)'] = df2['Amount($)'].str.replace('Undisclosed', '0', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)'] = df2['Amount($)'].astype(float)\n",
    "type(df2['Amount($)'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Amount($)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['HeadQuarter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.insert(6,\"Funding Year\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Company Name':'Company',\n",
    "                        'Industry':'Sector',\n",
    "                        'Amount':'Amount',\n",
    "                        'About Company':'About',\n",
    "                        'Round/Series' : 'Stage'},\n",
    "             inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
